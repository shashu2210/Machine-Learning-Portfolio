{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import metrics\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from scipy import stats\n",
    "import xgboost as xgb\n",
    "\n",
    "\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, precision_score, recall_score\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "from sklearn.model_selection import RandomizedSearchCV, train_test_split\n",
    "from scipy.stats import randint\n",
    "\n",
    "input_path='C:\\\\Users\\\\varsh\\\\Documents\\\\Kaggle\\\\Purchase Prediction\\\\varshini_share\\\\input\\\\'\n",
    "output_path='C:\\\\Users\\\\varsh\\\\Documents\\\\Kaggle\\\\Purchase Prediction\\\\varshini_share\\\\output\\\\'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1). Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(665249, 25)\n",
      "(198856, 25)\n",
      "(864105, 25)\n"
     ]
    }
   ],
   "source": [
    "#Importing the data\n",
    "train=pd.read_csv(input_path+\"train.csv\")\n",
    "test=pd.read_csv(input_path+\"test.csv\")\n",
    "print(train.shape)\n",
    "print(test.shape)\n",
    "\n",
    "#Combining train and test in to a single dataframe to do the data prep together\n",
    "frames = [train, test]\n",
    "my_data = pd.concat(frames,keys=['train', 'test'])\n",
    "print(my_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Column-wise Null value counts\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "customer_ID          0\n",
       "shopping_pt          0\n",
       "record_type          0\n",
       "day                  0\n",
       "time                 0\n",
       "state                0\n",
       "group_size           0\n",
       "homeowner            0\n",
       "car_age              0\n",
       "car_value            0\n",
       "age_oldest           0\n",
       "age_youngest         0\n",
       "married_couple       0\n",
       "C_previous           0\n",
       "duration_previous    0\n",
       "A                    0\n",
       "B                    0\n",
       "C                    0\n",
       "D                    0\n",
       "E                    0\n",
       "F                    0\n",
       "G                    0\n",
       "cost                 0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Imputing the NAs from vairables\n",
    "my_data['location'] = my_data['location'].fillna(0)\n",
    "my_data['C_previous'] = my_data['C_previous'].fillna(99)\n",
    "my_data['duration_previous'] = my_data['duration_previous'].fillna(99)\n",
    "my_data['car_value'] = my_data['car_value'].fillna(99)\n",
    "\n",
    "#Risk factor has a lot of NA values and remaining two are ID variables\n",
    "cols_to_remove=['location','risk_factor']\n",
    "my_data=my_data.drop(cols_to_remove,axis=1)\n",
    "\n",
    "#printing column wise null value counts\n",
    "print(\"Column-wise Null value counts\")\n",
    "my_data.isnull().sum(axis = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### One hot encoding of catergorical columns and converting time in to a cyclical variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function for one hot encoding\n",
    "def one_hot(df, cols):\n",
    "    for col in cols:\n",
    "        df[col] = df[col].astype('category')\n",
    "    df=pd.concat([df,pd.get_dummies(df[cols])], axis=1)\n",
    "    df.drop(cols, axis=1, inplace=True)\n",
    "    return df\n",
    "\n",
    "#Function to convert time in to a cyclical variable\n",
    "def time_convert(df):\n",
    "    df['time'] = df['time'].apply(lambda x: (int(x[:2]) * 60) + int(x[3:]))\n",
    "    df['time_sin'] = np.sin((df['time'] * np.pi) / 1800)\n",
    "    df['time_cos'] = np.cos((df['time'] * np.pi) / 1800)\n",
    "    df = df.drop(['time'], axis=1)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Applying the above functions\n",
    "# cat_cols = ['shopping_pt','day', 'state',\n",
    "#        'group_size', 'homeowner', 'car_age','car_value', 'age_oldest', 'age_youngest',\n",
    "#        'married_couple','C_previous','duration_previous']\n",
    "\n",
    "cat_cols = ['shopping_pt','day', 'state','group_size', 'homeowner','car_value','married_couple','C_previous']\n",
    "\n",
    "my_data = one_hot(my_data,cat_cols)\n",
    "my_data = time_convert(my_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Splitting the dataset in to Test and Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(665249, 95)\n",
      "(198856, 95)\n"
     ]
    }
   ],
   "source": [
    "#Split data back in to train & Test\n",
    "my_train=my_data.loc['train']\n",
    "my_test=my_data.loc['test']\n",
    "print(my_train.shape)\n",
    "print(my_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function that Lags the policy information to get the Previous 'K' policies as columns to our data - Both Train &Test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\varsh\\AppData\\Local\\Temp\\ipykernel_40536\\2692081912.py:11: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  my_train.loc[:,'{}_previous_{}'.format(col,i)]=my_train.loc[:,'{}'.format(col)].shift(i).fillna(99)\n",
      "C:\\Users\\varsh\\AppData\\Local\\Temp\\ipykernel_40536\\2692081912.py:12: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  my_test.loc[:,'{}_previous_{}'.format(col,i)]=my_test['{}'.format(col)].shift(i).fillna(99)\n",
      "C:\\Users\\varsh\\AppData\\Local\\Temp\\ipykernel_40536\\2692081912.py:11: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  my_train.loc[:,'{}_previous_{}'.format(col,i)]=my_train.loc[:,'{}'.format(col)].shift(i).fillna(99)\n",
      "C:\\Users\\varsh\\AppData\\Local\\Temp\\ipykernel_40536\\2692081912.py:12: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  my_test.loc[:,'{}_previous_{}'.format(col,i)]=my_test['{}'.format(col)].shift(i).fillna(99)\n",
      "C:\\Users\\varsh\\AppData\\Local\\Temp\\ipykernel_40536\\2692081912.py:11: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  my_train.loc[:,'{}_previous_{}'.format(col,i)]=my_train.loc[:,'{}'.format(col)].shift(i).fillna(99)\n",
      "C:\\Users\\varsh\\AppData\\Local\\Temp\\ipykernel_40536\\2692081912.py:12: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  my_test.loc[:,'{}_previous_{}'.format(col,i)]=my_test['{}'.format(col)].shift(i).fillna(99)\n",
      "C:\\Users\\varsh\\AppData\\Local\\Temp\\ipykernel_40536\\2692081912.py:11: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  my_train.loc[:,'{}_previous_{}'.format(col,i)]=my_train.loc[:,'{}'.format(col)].shift(i).fillna(99)\n",
      "C:\\Users\\varsh\\AppData\\Local\\Temp\\ipykernel_40536\\2692081912.py:12: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  my_test.loc[:,'{}_previous_{}'.format(col,i)]=my_test['{}'.format(col)].shift(i).fillna(99)\n",
      "C:\\Users\\varsh\\AppData\\Local\\Temp\\ipykernel_40536\\2692081912.py:11: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  my_train.loc[:,'{}_previous_{}'.format(col,i)]=my_train.loc[:,'{}'.format(col)].shift(i).fillna(99)\n",
      "C:\\Users\\varsh\\AppData\\Local\\Temp\\ipykernel_40536\\2692081912.py:12: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  my_test.loc[:,'{}_previous_{}'.format(col,i)]=my_test['{}'.format(col)].shift(i).fillna(99)\n",
      "C:\\Users\\varsh\\AppData\\Local\\Temp\\ipykernel_40536\\2692081912.py:11: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  my_train.loc[:,'{}_previous_{}'.format(col,i)]=my_train.loc[:,'{}'.format(col)].shift(i).fillna(99)\n",
      "C:\\Users\\varsh\\AppData\\Local\\Temp\\ipykernel_40536\\2692081912.py:12: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  my_test.loc[:,'{}_previous_{}'.format(col,i)]=my_test['{}'.format(col)].shift(i).fillna(99)\n",
      "C:\\Users\\varsh\\AppData\\Local\\Temp\\ipykernel_40536\\2692081912.py:11: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  my_train.loc[:,'{}_previous_{}'.format(col,i)]=my_train.loc[:,'{}'.format(col)].shift(i).fillna(99)\n",
      "C:\\Users\\varsh\\AppData\\Local\\Temp\\ipykernel_40536\\2692081912.py:12: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  my_test.loc[:,'{}_previous_{}'.format(col,i)]=my_test['{}'.format(col)].shift(i).fillna(99)\n",
      "C:\\Users\\varsh\\AppData\\Local\\Temp\\ipykernel_40536\\2692081912.py:11: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  my_train.loc[:,'{}_previous_{}'.format(col,i)]=my_train.loc[:,'{}'.format(col)].shift(i).fillna(99)\n",
      "C:\\Users\\varsh\\AppData\\Local\\Temp\\ipykernel_40536\\2692081912.py:12: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  my_test.loc[:,'{}_previous_{}'.format(col,i)]=my_test['{}'.format(col)].shift(i).fillna(99)\n",
      "C:\\Users\\varsh\\AppData\\Local\\Temp\\ipykernel_40536\\2692081912.py:11: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  my_train.loc[:,'{}_previous_{}'.format(col,i)]=my_train.loc[:,'{}'.format(col)].shift(i).fillna(99)\n",
      "C:\\Users\\varsh\\AppData\\Local\\Temp\\ipykernel_40536\\2692081912.py:12: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  my_test.loc[:,'{}_previous_{}'.format(col,i)]=my_test['{}'.format(col)].shift(i).fillna(99)\n",
      "C:\\Users\\varsh\\AppData\\Local\\Temp\\ipykernel_40536\\2692081912.py:11: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  my_train.loc[:,'{}_previous_{}'.format(col,i)]=my_train.loc[:,'{}'.format(col)].shift(i).fillna(99)\n",
      "C:\\Users\\varsh\\AppData\\Local\\Temp\\ipykernel_40536\\2692081912.py:12: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  my_test.loc[:,'{}_previous_{}'.format(col,i)]=my_test['{}'.format(col)].shift(i).fillna(99)\n",
      "C:\\Users\\varsh\\AppData\\Local\\Temp\\ipykernel_40536\\2692081912.py:11: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  my_train.loc[:,'{}_previous_{}'.format(col,i)]=my_train.loc[:,'{}'.format(col)].shift(i).fillna(99)\n",
      "C:\\Users\\varsh\\AppData\\Local\\Temp\\ipykernel_40536\\2692081912.py:12: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  my_test.loc[:,'{}_previous_{}'.format(col,i)]=my_test['{}'.format(col)].shift(i).fillna(99)\n",
      "C:\\Users\\varsh\\AppData\\Local\\Temp\\ipykernel_40536\\2692081912.py:11: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  my_train.loc[:,'{}_previous_{}'.format(col,i)]=my_train.loc[:,'{}'.format(col)].shift(i).fillna(99)\n",
      "C:\\Users\\varsh\\AppData\\Local\\Temp\\ipykernel_40536\\2692081912.py:12: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  my_test.loc[:,'{}_previous_{}'.format(col,i)]=my_test['{}'.format(col)].shift(i).fillna(99)\n",
      "C:\\Users\\varsh\\AppData\\Local\\Temp\\ipykernel_40536\\2692081912.py:11: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  my_train.loc[:,'{}_previous_{}'.format(col,i)]=my_train.loc[:,'{}'.format(col)].shift(i).fillna(99)\n",
      "C:\\Users\\varsh\\AppData\\Local\\Temp\\ipykernel_40536\\2692081912.py:12: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  my_test.loc[:,'{}_previous_{}'.format(col,i)]=my_test['{}'.format(col)].shift(i).fillna(99)\n",
      "C:\\Users\\varsh\\AppData\\Local\\Temp\\ipykernel_40536\\2692081912.py:11: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  my_train.loc[:,'{}_previous_{}'.format(col,i)]=my_train.loc[:,'{}'.format(col)].shift(i).fillna(99)\n",
      "C:\\Users\\varsh\\AppData\\Local\\Temp\\ipykernel_40536\\2692081912.py:12: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  my_test.loc[:,'{}_previous_{}'.format(col,i)]=my_test['{}'.format(col)].shift(i).fillna(99)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(864105, 109)\n",
      "(665249, 153)\n",
      "(198856, 153)\n"
     ]
    }
   ],
   "source": [
    "# Experiment with different values of K\n",
    "K=3\n",
    "\n",
    "cols_to_lag=['A','B','C','D','E','F','G']\n",
    "lagged_cols=[]\n",
    "\n",
    "#Lagging\n",
    "for col in cols_to_lag:\n",
    "    for i in range(1,K):\n",
    "        lagged_cols.append('{}_previous_{}'.format(col,i))\n",
    "        my_train.loc[:,'{}_previous_{}'.format(col,i)]=my_train.loc[:,'{}'.format(col)].shift(i).fillna(99)\n",
    "        my_test.loc[:,'{}_previous_{}'.format(col,i)]=my_test['{}'.format(col)].shift(i).fillna(99)\n",
    "frames = [my_train, my_test]\n",
    "my_data = pd.concat(frames,keys=['train', 'test'])\n",
    "print(my_data.shape)\n",
    "\n",
    "\n",
    "#one-hot encoding the lagged variables\n",
    "my_data = one_hot(my_data,lagged_cols)\n",
    "my_train=my_data.loc['train']\n",
    "my_test=my_data.loc['test']\n",
    "print(my_train.shape)\n",
    "print(my_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>customer_ID</th>\n",
       "      <th>record_type</th>\n",
       "      <th>car_age</th>\n",
       "      <th>age_oldest</th>\n",
       "      <th>age_youngest</th>\n",
       "      <th>duration_previous</th>\n",
       "      <th>A</th>\n",
       "      <th>B</th>\n",
       "      <th>C</th>\n",
       "      <th>D</th>\n",
       "      <th>...</th>\n",
       "      <th>G_previous_1_1.0</th>\n",
       "      <th>G_previous_1_2.0</th>\n",
       "      <th>G_previous_1_3.0</th>\n",
       "      <th>G_previous_1_4.0</th>\n",
       "      <th>G_previous_1_99.0</th>\n",
       "      <th>G_previous_2_1.0</th>\n",
       "      <th>G_previous_2_2.0</th>\n",
       "      <th>G_previous_2_3.0</th>\n",
       "      <th>G_previous_2_4.0</th>\n",
       "      <th>G_previous_2_99.0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10000000</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>46</td>\n",
       "      <td>42</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10000000</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>46</td>\n",
       "      <td>42</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10000000</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>46</td>\n",
       "      <td>42</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10000000</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>46</td>\n",
       "      <td>42</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10000000</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>46</td>\n",
       "      <td>42</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 153 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   customer_ID  record_type  car_age  age_oldest  age_youngest  \\\n",
       "0     10000000            0        2          46            42   \n",
       "1     10000000            0        2          46            42   \n",
       "2     10000000            0        2          46            42   \n",
       "3     10000000            0        2          46            42   \n",
       "4     10000000            0        2          46            42   \n",
       "\n",
       "   duration_previous  A  B  C  D  ...  G_previous_1_1.0  G_previous_1_2.0  \\\n",
       "0                2.0  1  0  2  2  ...                 0                 0   \n",
       "1                2.0  1  0  2  2  ...                 0                 1   \n",
       "2                2.0  1  0  2  2  ...                 1                 0   \n",
       "3                2.0  1  0  2  2  ...                 1                 0   \n",
       "4                2.0  1  0  2  2  ...                 1                 0   \n",
       "\n",
       "   G_previous_1_3.0  G_previous_1_4.0  G_previous_1_99.0  G_previous_2_1.0  \\\n",
       "0                 0                 0                  1                 0   \n",
       "1                 0                 0                  0                 0   \n",
       "2                 0                 0                  0                 0   \n",
       "3                 0                 0                  0                 1   \n",
       "4                 0                 0                  0                 1   \n",
       "\n",
       "   G_previous_2_2.0  G_previous_2_3.0  G_previous_2_4.0  G_previous_2_99.0  \n",
       "0                 0                 0                 0                  1  \n",
       "1                 0                 0                 0                  1  \n",
       "2                 1                 0                 0                  0  \n",
       "3                 0                 0                 0                  0  \n",
       "4                 0                 0                 0                  0  \n",
       "\n",
       "[5 rows x 153 columns]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>customer_ID</th>\n",
       "      <th>record_type</th>\n",
       "      <th>car_age</th>\n",
       "      <th>age_oldest</th>\n",
       "      <th>age_youngest</th>\n",
       "      <th>duration_previous</th>\n",
       "      <th>A</th>\n",
       "      <th>B</th>\n",
       "      <th>C</th>\n",
       "      <th>D</th>\n",
       "      <th>...</th>\n",
       "      <th>G_previous_1_1.0</th>\n",
       "      <th>G_previous_1_2.0</th>\n",
       "      <th>G_previous_1_3.0</th>\n",
       "      <th>G_previous_1_4.0</th>\n",
       "      <th>G_previous_1_99.0</th>\n",
       "      <th>G_previous_2_1.0</th>\n",
       "      <th>G_previous_2_2.0</th>\n",
       "      <th>G_previous_2_3.0</th>\n",
       "      <th>G_previous_2_4.0</th>\n",
       "      <th>G_previous_2_99.0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10000001</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>24</td>\n",
       "      <td>24</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10000001</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>24</td>\n",
       "      <td>24</td>\n",
       "      <td>9.0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10000002</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>74</td>\n",
       "      <td>74</td>\n",
       "      <td>15.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10000002</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>74</td>\n",
       "      <td>74</td>\n",
       "      <td>15.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10000003</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>26</td>\n",
       "      <td>26</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 153 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   customer_ID  record_type  car_age  age_oldest  age_youngest  \\\n",
       "0     10000001            0        9          24            24   \n",
       "1     10000001            0        9          24            24   \n",
       "2     10000002            0        7          74            74   \n",
       "3     10000002            0        7          74            74   \n",
       "4     10000003            0        4          26            26   \n",
       "\n",
       "   duration_previous  A  B  C  D  ...  G_previous_1_1.0  G_previous_1_2.0  \\\n",
       "0                9.0  0  0  1  1  ...                 0                 0   \n",
       "1                9.0  2  1  1  3  ...                 0                 0   \n",
       "2               15.0  2  0  2  3  ...                 0                 1   \n",
       "3               15.0  2  0  2  3  ...                 0                 1   \n",
       "4                1.0  1  0  1  1  ...                 0                 1   \n",
       "\n",
       "   G_previous_1_3.0  G_previous_1_4.0  G_previous_1_99.0  G_previous_2_1.0  \\\n",
       "0                 0                 0                  1                 0   \n",
       "1                 0                 1                  0                 0   \n",
       "2                 0                 0                  0                 0   \n",
       "3                 0                 0                  0                 0   \n",
       "4                 0                 0                  0                 0   \n",
       "\n",
       "   G_previous_2_2.0  G_previous_2_3.0  G_previous_2_4.0  G_previous_2_99.0  \n",
       "0                 0                 0                 0                  1  \n",
       "1                 0                 0                 0                  1  \n",
       "2                 0                 0                 1                  0  \n",
       "3                 1                 0                 0                  0  \n",
       "4                 1                 0                 0                  0  \n",
       "\n",
       "[5 rows x 153 columns]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TRAIN DATA-  Filtering only the rows with the purchased flag(record type=1) and renaming the policy variables to \"Purchased\" - which will the response variable for each indivdual model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>customer_ID</th>\n",
       "      <th>record_type</th>\n",
       "      <th>car_age</th>\n",
       "      <th>age_oldest</th>\n",
       "      <th>age_youngest</th>\n",
       "      <th>duration_previous</th>\n",
       "      <th>A_purchased</th>\n",
       "      <th>B_purchased</th>\n",
       "      <th>C_purchased</th>\n",
       "      <th>D_purchased</th>\n",
       "      <th>...</th>\n",
       "      <th>G_previous_1_1.0</th>\n",
       "      <th>G_previous_1_2.0</th>\n",
       "      <th>G_previous_1_3.0</th>\n",
       "      <th>G_previous_1_4.0</th>\n",
       "      <th>G_previous_1_99.0</th>\n",
       "      <th>G_previous_2_1.0</th>\n",
       "      <th>G_previous_2_2.0</th>\n",
       "      <th>G_previous_2_3.0</th>\n",
       "      <th>G_previous_2_4.0</th>\n",
       "      <th>G_previous_2_99.0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>10000000</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>46</td>\n",
       "      <td>42</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>10000005</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>28</td>\n",
       "      <td>28</td>\n",
       "      <td>13.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>10000007</td>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "      <td>43</td>\n",
       "      <td>43</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>10000013</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>62</td>\n",
       "      <td>60</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>10000014</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>32</td>\n",
       "      <td>28</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 153 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    customer_ID  record_type  car_age  age_oldest  age_youngest  \\\n",
       "8      10000000            1        2          46            42   \n",
       "14     10000005            1       10          28            28   \n",
       "22     10000007            1       11          43            43   \n",
       "26     10000013            1        3          62            60   \n",
       "32     10000014            1        5          32            28   \n",
       "\n",
       "    duration_previous  A_purchased  B_purchased  C_purchased  D_purchased  \\\n",
       "8                 2.0            1            0            2            2   \n",
       "14               13.0            0            0            3            2   \n",
       "22                4.0            0            0            1            2   \n",
       "26                3.0            1            1            3            2   \n",
       "32                2.0            1            1            1            1   \n",
       "\n",
       "    ...  G_previous_1_1.0  G_previous_1_2.0  G_previous_1_3.0  \\\n",
       "8   ...                 1                 0                 0   \n",
       "14  ...                 0                 1                 0   \n",
       "22  ...                 1                 0                 0   \n",
       "26  ...                 0                 0                 1   \n",
       "32  ...                 0                 1                 0   \n",
       "\n",
       "    G_previous_1_4.0  G_previous_1_99.0  G_previous_2_1.0  G_previous_2_2.0  \\\n",
       "8                  0                  0                 1                 0   \n",
       "14                 0                  0                 0                 1   \n",
       "22                 0                  0                 1                 0   \n",
       "26                 0                  0                 0                 0   \n",
       "32                 0                  0                 0                 1   \n",
       "\n",
       "    G_previous_2_3.0  G_previous_2_4.0  G_previous_2_99.0  \n",
       "8                  0                 0                  0  \n",
       "14                 0                 0                  0  \n",
       "22                 0                 0                  0  \n",
       "26                 1                 0                  0  \n",
       "32                 0                 0                  0  \n",
       "\n",
       "[5 rows x 153 columns]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_train = my_train[my_train['record_type'] == 1]\n",
    "\n",
    "#renaming the columns to \"{policyname}_purchased\"\n",
    "my_train=my_train.rename(columns={\"A\": \"A_purchased\",\"B\": \"B_purchased\",\"C\": \"C_purchased\",\"D\": \"D_purchased\",\n",
    "                                  \"E\": \"E_purchased\",\"F\": \"F_purchased\",\"G\": \"G_purchased\"})\n",
    "\n",
    "\n",
    "\n",
    "# options=['A','B','C','D','E','F','G']\n",
    "# for col in options:\n",
    "#      my_train['{}_purchased'.format(col)]=my_train[col]\n",
    "\n",
    "my_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TEST DATA - Retaining only the purchased data rows for the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>customer_ID</th>\n",
       "      <th>record_type</th>\n",
       "      <th>car_age</th>\n",
       "      <th>age_oldest</th>\n",
       "      <th>age_youngest</th>\n",
       "      <th>duration_previous</th>\n",
       "      <th>A</th>\n",
       "      <th>B</th>\n",
       "      <th>C</th>\n",
       "      <th>D</th>\n",
       "      <th>...</th>\n",
       "      <th>G_previous_1_1.0</th>\n",
       "      <th>G_previous_1_2.0</th>\n",
       "      <th>G_previous_1_3.0</th>\n",
       "      <th>G_previous_1_4.0</th>\n",
       "      <th>G_previous_1_99.0</th>\n",
       "      <th>G_previous_2_1.0</th>\n",
       "      <th>G_previous_2_2.0</th>\n",
       "      <th>G_previous_2_3.0</th>\n",
       "      <th>G_previous_2_4.0</th>\n",
       "      <th>G_previous_2_99.0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10000001</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>24</td>\n",
       "      <td>24</td>\n",
       "      <td>9.0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10000002</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>74</td>\n",
       "      <td>74</td>\n",
       "      <td>15.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10000003</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>26</td>\n",
       "      <td>26</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10000004</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>22</td>\n",
       "      <td>22</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10000006</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>27</td>\n",
       "      <td>27</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 153 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   customer_ID  record_type  car_age  age_oldest  age_youngest  \\\n",
       "0     10000001            0        9          24            24   \n",
       "1     10000002            0        7          74            74   \n",
       "2     10000003            0        4          26            26   \n",
       "3     10000004            0       13          22            22   \n",
       "4     10000006            0       11          27            27   \n",
       "\n",
       "   duration_previous  A  B  C  D  ...  G_previous_1_1.0  G_previous_1_2.0  \\\n",
       "0                9.0  2  1  1  3  ...                 0                 0   \n",
       "1               15.0  2  0  2  3  ...                 0                 1   \n",
       "2                1.0  1  0  2  1  ...                 0                 1   \n",
       "3                3.0  2  0  1  1  ...                 0                 0   \n",
       "4               12.0  0  0  1  1  ...                 1                 0   \n",
       "\n",
       "   G_previous_1_3.0  G_previous_1_4.0  G_previous_1_99.0  G_previous_2_1.0  \\\n",
       "0                 0                 1                  0                 0   \n",
       "1                 0                 0                  0                 0   \n",
       "2                 0                 0                  0                 0   \n",
       "3                 1                 0                  0                 0   \n",
       "4                 0                 0                  0                 0   \n",
       "\n",
       "   G_previous_2_2.0  G_previous_2_3.0  G_previous_2_4.0  G_previous_2_99.0  \n",
       "0                 0                 0                 0                  1  \n",
       "1                 1                 0                 0                  0  \n",
       "2                 1                 0                 0                  0  \n",
       "3                 0                 0                 1                  0  \n",
       "4                 0                 1                 0                  0  \n",
       "\n",
       "[5 rows x 153 columns]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#We are taking the last row for each customer from the test data\n",
    "my_test=my_test.groupby('customer_ID').last()\n",
    "my_test=my_test.reset_index()\n",
    "my_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(97009, 153)\n",
      "(55716, 153)\n"
     ]
    }
   ],
   "source": [
    "print(my_train.shape)\n",
    "print(my_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BREAKDOWN OF THIS PROBLEM IN TO A MODEL FOR EACH OPTION NAME"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model 1 - Predicts G\n",
    "# Model 2 - Predicts C\n",
    "# Model 3-  Predicts D ( uses Predicted C as an added column in the model) DECIDED BASED ON CORRELATION\n",
    "# Model 4-  Predicts A \n",
    "# Model 5-  Predicts F ( uses Predicted A as an added column in the model) DECIDED BASED ON CORRELATION\n",
    "# Model 6-  Predicts B \n",
    "# Model 7-  Predicts E ( uses Predicted B as an added column in the model) DECIDED BASED ON CORRELATION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. MODEL TRAINING AND PREDICTION - FUNCTIONS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### REFER TO THE HYPER PARAMETER TUNING RESULTS CODE FOR THESE VALUES\n",
    "\n",
    "### Model 1 Hyper paprameter tuning results- Prediction of G\n",
    "Best hyperparameters for XGboost: {'max_depth': 6, 'min_child_weight': 4, 'n_estimators': 72}\n",
    "\n",
    "Best hyperparameters for random forest: {'max_depth': 9, 'n_estimators': 90}\n",
    "\n",
    "\n",
    "### Model 2 Hyper paprameter tuning results- Prediction of C\n",
    "\n",
    "Best hyperparameters for XGboost: {'max_depth': 4, 'min_child_weight': 2, 'n_estimators': 70}\n",
    "\n",
    "Best hyperparameters for random forest: {'max_depth': 8, 'n_estimators': 154}\n",
    "\n",
    "\n",
    "### Model 3 Hyper paprameter tuning results- Prediction of D\n",
    "\n",
    "Best hyperparameters for XGboost: {'max_depth': 3, 'min_child_weight': 3, 'n_estimators': 107}\n",
    "\n",
    "Best hyperparameters for random forest: {'max_depth': 9, 'n_estimators': 223}\n",
    "\n",
    "\n",
    "### Model 4 Hyper paprameter tuning results- Prediction of A\n",
    "\n",
    "Best hyperparameters for XGboost: {'max_depth': 5, 'min_child_weight': 1, 'n_estimators': 87}\n",
    "\n",
    "Best hyperparameters for random forest: {'max_depth': 7, 'n_estimators': 197}\n",
    "\n",
    "\n",
    "### Model 5 Hyper paprameter tuning results- Prediction of F\n",
    "\n",
    "Best hyperparameters for XGboost: {'max_depth': 4, 'min_child_weight': 3, 'n_estimators': 115}\n",
    "\n",
    "Best hyperparameters for random forest: {'max_depth': 9, 'n_estimators': 247}\n",
    "\n",
    "\n",
    "### Model 6 Hyper paprameter tuning results- Prediction of B\n",
    "\n",
    "Best hyperparameters for XGboost: {'max_depth': 3, 'min_child_weight': 2, 'n_estimators': 274}\n",
    "\n",
    "Best hyperparameters for random forest: {'max_depth': 4, 'n_estimators': 277}\n",
    "\n",
    "\n",
    "### Model 7 Hyper paprameter tuning results- Prediction of E\n",
    "\n",
    "Best hyperparameters for XGboost: {'max_depth': 3, 'min_child_weight': 3, 'n_estimators': 262}\n",
    "\n",
    "Best hyperparameters for random forest: {'max_depth': 9, 'n_estimators': 256}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Below function trains the model\n",
    "def model_train(data,response_column,cols_to_drop,method='logistic',rf_parameters=None,xgb_parameters=None ):\n",
    "    \n",
    "    \n",
    "    num_class=len(data[response_column].unique())\n",
    "    y = data[response_column]\n",
    "    X = data.copy()\n",
    "    X.drop(cols_to_drop, axis=1, inplace=True)\n",
    "    \n",
    "    X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=101, stratify=y)\n",
    "    print(\"Training data size\", X_train.shape)\n",
    "    print(\"validation data size\", X_val.shape)\n",
    "    \n",
    "    if(method=='logistic'):\n",
    "        print(\"\\nUsing Logistic regression:\\n\")\n",
    "        logreg = LogisticRegression(solver='lbfgs', max_iter=300)\n",
    "        logreg.fit(X_train, y_train)\n",
    "        y_pred_val=logreg.predict(X_val)\n",
    "        y_pred_prob_val=logreg.predict_proba(X_val) \n",
    "        metrics.confusion_matrix(y_val,y_pred_val)\n",
    "        print(\"Classification Report\\n\",classification_report(y_val,y_pred_val))\n",
    "        print(\"Accuracy:  \", accuracy_score(y_val, y_pred_val))\n",
    "        \n",
    "    elif(method=='random_forest'):\n",
    "        print(\"\\nUsing random_forest:\\n'\")\n",
    "        rf = RandomForestClassifier(**rf_parameters)\n",
    "        rf.fit(X_train, y_train)\n",
    "\n",
    "        y_pred_val=rf.predict(X_val)\n",
    "        y_pred_prob_val=rf.predict_proba(X_val) \n",
    "        metrics.confusion_matrix(y_val,y_pred_val)\n",
    "        print(\"Using Random Forest - classification_report\",classification_report(y_val,y_pred_val))\n",
    "        print(\"Using Random Forest - Overall accuracy\", accuracy_score(y_val, y_pred_val))\n",
    "        \n",
    "        \n",
    "    elif(method=='XGBOOST'):\n",
    "        print(\"\\nUsing XGBOOST:\\n'\")\n",
    "        \n",
    "        #iF TIME PERMITS DO PARAMETER TUNING AND REFINE THESE VALUES - Experiment with different parameters\n",
    "        xgb_model = xgb.XGBClassifier(**xgb_parameters)\n",
    "        xgb_model.fit(X_train, y_train)\n",
    "\n",
    "        y_pred_val=xgb_model.predict(X_val)\n",
    "        metrics.confusion_matrix(y_val,y_pred_val)\n",
    "        print(\"Using XGBOOST - classification_report\",classification_report(y_val,y_pred_val))\n",
    "        print(\"Using XGBOOST - Overall accuracy\", accuracy_score(y_val, y_pred_val))\n",
    "\n",
    "        return None\n",
    "    \n",
    "#Below function predicts on the test data provided\n",
    "def model_predict(build_data,test_data,response_column,train_cols_to_drop,test_cols_to_drop,method='logistic',rf_parameters=None,xgb_parameters=None):\n",
    "    \n",
    "    y = build_data[response_column]\n",
    "    X = build_data.copy()\n",
    "    X.drop(train_cols_to_drop, axis=1, inplace=True)\n",
    "    test_data_new=test_data.drop(test_cols_to_drop, axis=1)\n",
    "    \n",
    "    num_class=len(build_data[response_column].unique())\n",
    "    if(method=='logistic'):\n",
    "        logreg = LogisticRegression(solver='lbfgs', max_iter=300)\n",
    "        logreg.fit(X, y)\n",
    "        output=logreg.predict(test_data_new)\n",
    "\n",
    "        \n",
    "    elif(method=='random_forest'):\n",
    "        rf = RandomForestClassifier(**rf_parameters)\n",
    "        rf.fit(X, y)\n",
    "        test_data_new = test_data_new[X.columns]\n",
    "        output=rf.predict(test_data_new)\n",
    "    \n",
    "    \n",
    "    #Experiment with different parameters\n",
    "    elif(method=='XGBOOST'):\n",
    "        xgb_model = xgb.XGBClassifier(**xgb_parameters)\n",
    "        xgb_model.fit(X, y)\n",
    "        test_data_new = test_data_new[X.columns]\n",
    "        output=xgb_model.predict(test_data_new)\n",
    "        \n",
    "        \n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def combine_sub_models_train(build_data,test_data,method='logistic'):\n",
    "    \n",
    "    \n",
    "    train_cols_to_drop_model_G=['record_type','customer_ID','A_purchased','B_purchased','C_purchased',\n",
    "    'D_purchased','E_purchased','F_purchased','G_purchased']\n",
    "    train_cols_to_drop_model_C=['record_type','customer_ID','A_purchased','B_purchased','C_purchased',\n",
    "        'D_purchased','E_purchased','F_purchased','G_purchased']\n",
    "    train_cols_to_drop_model_D=['record_type','customer_ID','A_purchased','B_purchased',\n",
    "        'D_purchased','E_purchased','F_purchased','G_purchased']\n",
    "    train_cols_to_drop_model_A=['record_type','customer_ID','A_purchased','B_purchased','C_purchased',\n",
    "        'D_purchased','E_purchased','F_purchased','G_purchased']\n",
    "    train_cols_to_drop_model_F=['record_type','customer_ID','B_purchased','C_purchased',\n",
    "        'D_purchased','E_purchased','F_purchased','G_purchased']\n",
    "    train_cols_to_drop_model_B=['record_type','customer_ID','A_purchased','B_purchased','C_purchased',\n",
    "        'D_purchased','E_purchased','F_purchased','G_purchased']\n",
    "    train_cols_to_drop_model_E=['record_type','customer_ID','A_purchased','C_purchased',\n",
    "        'D_purchased','E_purchased','F_purchased','G_purchased']\n",
    "    \n",
    "    \n",
    "    \n",
    "    XGB_params_G= {'max_depth': 6, 'min_child_weight': 4, 'n_estimators': 72}\n",
    "    rf_params_G={'max_depth': 8, 'n_estimators': 154}\n",
    "\n",
    "    XGB_params_C= {'max_depth': 4, 'min_child_weight': 2, 'n_estimators': 70}\n",
    "    rf_params_C={'max_depth': 9, 'n_estimators': 90}\n",
    "\n",
    "    XGB_params_D= {'max_depth': 3, 'min_child_weight': 3, 'n_estimators': 107}\n",
    "    rf_params_D={'max_depth': 9, 'n_estimators': 223}\n",
    "\n",
    "    XGB_params_A= {'max_depth': 5, 'min_child_weight': 1, 'n_estimators': 87}\n",
    "    rf_params_A={'max_depth': 7, 'n_estimators': 197}\n",
    "\n",
    "    XGB_params_F= {'max_depth': 4, 'min_child_weight': 3, 'n_estimators': 115}\n",
    "    rf_params_F={'max_depth': 9, 'n_estimators': 247}\n",
    "\n",
    "    XGB_params_B= {'max_depth': 3, 'min_child_weight': 2, 'n_estimators': 274}\n",
    "    rf_params_B= {'max_depth': 4, 'n_estimators': 277}\n",
    "\n",
    "    XGB_params_E=  {'max_depth': 3, 'min_child_weight': 3, 'n_estimators': 262}\n",
    "    rf_params_E= {'max_depth': 9, 'n_estimators': 256}\n",
    "\n",
    "   \n",
    "    \n",
    "    print(\"\\nModel 1 Training results- Prediction of G\\n\\n\")\n",
    "    model_train(build_data,'G_purchased', train_cols_to_drop_model_G,method,rf_params_G,XGB_params_G)\n",
    "    \n",
    "    print(\"\\nModel 2 Training results- Prediction of C\\n\\n\")\n",
    "    model_train(build_data,'C_purchased', train_cols_to_drop_model_C,method,rf_params_C,XGB_params_C)\n",
    "    \n",
    "    print(\"\\nModel 3 Training results- Prediction of D\\n\\n\")\n",
    "    model_train(build_data,'D_purchased', train_cols_to_drop_model_D,method,rf_params_D,XGB_params_D)\n",
    "    \n",
    "    print(\"\\nModel 4 Training results- Prediction of A\\n\\n\")\n",
    "    model_train(build_data,'A_purchased', train_cols_to_drop_model_A,method,rf_params_A,XGB_params_A)\n",
    "    \n",
    "    print(\"\\nModel 5 Training results- Prediction of F\\n\\n\")\n",
    "    model_train(build_data,'F_purchased', train_cols_to_drop_model_F,method,rf_params_F,XGB_params_F)\n",
    "    \n",
    "    print(\"\\nModel 6 Training results- Prediction of B\\n\\n\")\n",
    "    model_train(build_data,'B_purchased', train_cols_to_drop_model_B,method,rf_params_B,XGB_params_B)\n",
    "    \n",
    "    print(\"\\nModel 7 Training results- Prediction of E\\n\\n\")\n",
    "    model_train(build_data,'E_purchased', train_cols_to_drop_model_E,method,rf_params_E,XGB_params_E)\n",
    "    \n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "def combine_sub_models_prediction(build_data,test_data,method='logistic'):\n",
    "    \n",
    "    train_cols_to_drop_model_G=['record_type','customer_ID','A_purchased','B_purchased','C_purchased',\n",
    "    'D_purchased','E_purchased','F_purchased','G_purchased']\n",
    "    train_cols_to_drop_model_C=['record_type','customer_ID','A_purchased','B_purchased','C_purchased',\n",
    "        'D_purchased','E_purchased','F_purchased','G_purchased']\n",
    "    train_cols_to_drop_model_D=['record_type','customer_ID','A_purchased','B_purchased',\n",
    "        'D_purchased','E_purchased','F_purchased','G_purchased']\n",
    "    train_cols_to_drop_model_A=['record_type','customer_ID','A_purchased','B_purchased','C_purchased',\n",
    "        'D_purchased','E_purchased','F_purchased','G_purchased']\n",
    "    train_cols_to_drop_model_F=['record_type','customer_ID','B_purchased','C_purchased',\n",
    "        'D_purchased','E_purchased','F_purchased','G_purchased']\n",
    "    train_cols_to_drop_model_B=['record_type','customer_ID','A_purchased','B_purchased','C_purchased',\n",
    "        'D_purchased','E_purchased','F_purchased','G_purchased']\n",
    "    train_cols_to_drop_model_E=['record_type','customer_ID','A_purchased','C_purchased',\n",
    "        'D_purchased','E_purchased','F_purchased','G_purchased']\n",
    "\n",
    "    test_cols_to_drop_model_G=['A','B','C','D','E','F','G','record_type','customer_ID']\n",
    "    test_cols_to_drop_model_C=['A','B','C','D','E','F','G','record_type','customer_ID']\n",
    "    test_cols_to_drop_model_D=['A','B','C','D','E','F','G','record_type','customer_ID']\n",
    "    test_cols_to_drop_model_A=['A','B','C','D','E','F','G','record_type','customer_ID']\n",
    "    test_cols_to_drop_model_F=['A','B','C','D','E','F','G','record_type','customer_ID']\n",
    "    test_cols_to_drop_model_B=['A','B','C','D','E','F','G','record_type','customer_ID']\n",
    "    test_cols_to_drop_model_E=['A','B','C','D','E','F','G','record_type','customer_ID']\n",
    "    \n",
    "    XGB_params_G= {'max_depth': 6, 'min_child_weight': 4, 'n_estimators': 72}\n",
    "    rf_params_G={'max_depth': 8, 'n_estimators': 154}\n",
    "\n",
    "    XGB_params_C= {'max_depth': 4, 'min_child_weight': 2, 'n_estimators': 70}\n",
    "    rf_params_C={'max_depth': 9, 'n_estimators': 90}\n",
    "\n",
    "    XGB_params_D= {'max_depth': 3, 'min_child_weight': 3, 'n_estimators': 107}\n",
    "    rf_params_D={'max_depth': 9, 'n_estimators': 223}\n",
    "\n",
    "    XGB_params_A= {'max_depth': 5, 'min_child_weight': 1, 'n_estimators': 87}\n",
    "    rf_params_A={'max_depth': 7, 'n_estimators': 197}\n",
    "\n",
    "    XGB_params_F= {'max_depth': 4, 'min_child_weight': 3, 'n_estimators': 115}\n",
    "    rf_params_F={'max_depth': 9, 'n_estimators': 247}\n",
    "\n",
    "    XGB_params_B= {'max_depth': 3, 'min_child_weight': 2, 'n_estimators': 274}\n",
    "    rf_params_B= {'max_depth': 4, 'n_estimators': 277}\n",
    "\n",
    "    XGB_params_E=  {'max_depth': 3, 'min_child_weight': 3, 'n_estimators': 262}\n",
    "    rf_params_E= {'max_depth': 9, 'n_estimators': 256}\n",
    "\n",
    "\n",
    "\n",
    "\t\n",
    "    \n",
    "    output_df=pd.DataFrame(my_test['customer_ID'])\n",
    "    \n",
    "    output_df['G_predicted']=model_predict(my_train,my_test,'G_purchased', train_cols_to_drop_model_G,test_cols_to_drop_model_G,\n",
    "                                           method,rf_params_G,XGB_params_G)\n",
    "    \n",
    "    output_df['C_predicted']=model_predict(my_train,my_test,'C_purchased', train_cols_to_drop_model_C,test_cols_to_drop_model_C,\n",
    "                                           method,rf_params_C,XGB_params_C)\n",
    "    \n",
    "    my_test['C_purchased']=output_df['C_predicted']\n",
    "    output_df['D_predicted']=model_predict(my_train,my_test,'D_purchased', train_cols_to_drop_model_D,test_cols_to_drop_model_D,\n",
    "                                           method,rf_params_D,XGB_params_D)\n",
    "    my_test.drop('C_purchased',axis=1,inplace=True)\n",
    "\n",
    "    output_df['A_predicted']=model_predict(my_train,my_test,'A_purchased', train_cols_to_drop_model_A,test_cols_to_drop_model_A,\n",
    "                                           method,rf_params_A,XGB_params_A)\n",
    "\n",
    "    my_test['A_purchased']=output_df['A_predicted']\n",
    "    output_df['F_predicted']=model_predict(my_train,my_test,'F_purchased', train_cols_to_drop_model_F,test_cols_to_drop_model_F,\n",
    "                                           method,rf_params_F,XGB_params_F)\n",
    "    my_test.drop('A_purchased',axis=1,inplace=True)\n",
    "\n",
    "    output_df['B_predicted']=model_predict(my_train,my_test,'B_purchased', train_cols_to_drop_model_B,test_cols_to_drop_model_B,\n",
    "                                           method,rf_params_B,XGB_params_B)\n",
    "      \n",
    "    my_test['B_purchased']=output_df['B_predicted']\n",
    "    output_df['E_predicted']=model_predict(my_train,my_test,'E_purchased', train_cols_to_drop_model_E,test_cols_to_drop_model_E,\n",
    "                                           method,rf_params_E,XGB_params_E)\n",
    "    my_test.drop('B_purchased',axis=1,inplace=True)\n",
    "\n",
    "    for C in output_df.columns:\n",
    "        output_df[C]=output_df[C].astype(str)\n",
    "    output_df['plan']=output_df['A_predicted'] + output_df['B_predicted'] + output_df['C_predicted'] + output_df['D_predicted'] + output_df['E_predicted'] + output_df['F_predicted'] + output_df['G_predicted']\n",
    "\n",
    "    return output_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. MODEL PREDICTIONS - USING LOGISTIC REGRESSION FOR ALL SUB MODELS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Models training results - using Logistic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Model 1 Training results- Prediction of G\n",
      "\n",
      "\n",
      "Training data size (77607, 144)\n",
      "validation data size (19402, 144)\n",
      "\n",
      "Using Logistic regression:\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\varsh\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.81      0.83      0.82      4051\n",
      "           2       0.84      0.89      0.87      7556\n",
      "           3       0.91      0.87      0.89      6140\n",
      "           4       0.85      0.69      0.76      1655\n",
      "\n",
      "    accuracy                           0.85     19402\n",
      "   macro avg       0.85      0.82      0.83     19402\n",
      "weighted avg       0.86      0.85      0.85     19402\n",
      "\n",
      "Accuracy:   0.8543449128955778\n",
      "\n",
      "Model 2 Training results- Prediction of C\n",
      "\n",
      "\n",
      "Training data size (77607, 144)\n",
      "validation data size (19402, 144)\n",
      "\n",
      "Using Logistic regression:\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\varsh\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.94      0.94      0.94      5799\n",
      "           2       0.90      0.89      0.90      4078\n",
      "           3       0.93      0.95      0.94      7593\n",
      "           4       0.94      0.88      0.91      1932\n",
      "\n",
      "    accuracy                           0.93     19402\n",
      "   macro avg       0.93      0.91      0.92     19402\n",
      "weighted avg       0.93      0.93      0.93     19402\n",
      "\n",
      "Accuracy:   0.9256262241006081\n",
      "\n",
      "Model 3 Training results- Prediction of D\n",
      "\n",
      "\n",
      "Training data size (77607, 145)\n",
      "validation data size (19402, 145)\n",
      "\n",
      "Using Logistic regression:\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\varsh\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.91      0.93      0.92      2525\n",
      "           2       0.91      0.91      0.91      4335\n",
      "           3       0.98      0.97      0.97     12542\n",
      "\n",
      "    accuracy                           0.95     19402\n",
      "   macro avg       0.93      0.94      0.93     19402\n",
      "weighted avg       0.95      0.95      0.95     19402\n",
      "\n",
      "Accuracy:   0.9513452221420472\n",
      "\n",
      "Model 4 Training results- Prediction of A\n",
      "\n",
      "\n",
      "Training data size (77607, 144)\n",
      "validation data size (19402, 144)\n",
      "\n",
      "Using Logistic regression:\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\varsh\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.92      0.93      4276\n",
      "           1       0.93      0.97      0.95     11916\n",
      "           2       0.90      0.80      0.84      3210\n",
      "\n",
      "    accuracy                           0.93     19402\n",
      "   macro avg       0.92      0.89      0.91     19402\n",
      "weighted avg       0.93      0.93      0.93     19402\n",
      "\n",
      "Accuracy:   0.9264508813524379\n",
      "\n",
      "Model 5 Training results- Prediction of F\n",
      "\n",
      "\n",
      "Training data size (77607, 145)\n",
      "validation data size (19402, 145)\n",
      "\n",
      "Using Logistic regression:\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\varsh\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.97      0.96      6249\n",
      "           1       0.92      0.91      0.92      4793\n",
      "           2       0.91      0.93      0.92      7234\n",
      "           3       0.85      0.74      0.79      1126\n",
      "\n",
      "    accuracy                           0.93     19402\n",
      "   macro avg       0.91      0.89      0.90     19402\n",
      "weighted avg       0.93      0.93      0.93     19402\n",
      "\n",
      "Accuracy:   0.9263477991959592\n",
      "\n",
      "Model 6 Training results- Prediction of B\n",
      "\n",
      "\n",
      "Training data size (77607, 144)\n",
      "validation data size (19402, 144)\n",
      "\n",
      "Using Logistic regression:\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\varsh\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.95      0.94     10165\n",
      "           1       0.94      0.92      0.93      9237\n",
      "\n",
      "    accuracy                           0.93     19402\n",
      "   macro avg       0.93      0.93      0.93     19402\n",
      "weighted avg       0.93      0.93      0.93     19402\n",
      "\n",
      "Accuracy:   0.933975878775384\n",
      "\n",
      "Model 7 Training results- Prediction of E\n",
      "\n",
      "\n",
      "Training data size (77607, 145)\n",
      "validation data size (19402, 145)\n",
      "\n",
      "Using Logistic regression:\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.95      0.95     10427\n",
      "           1       0.94      0.94      0.94      8975\n",
      "\n",
      "    accuracy                           0.94     19402\n",
      "   macro avg       0.94      0.94      0.94     19402\n",
      "weighted avg       0.94      0.94      0.94     19402\n",
      "\n",
      "Accuracy:   0.9445417998144521\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\varsh\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "combine_sub_models_train(my_train,my_test,'logistic')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Aggregating Model predictions in to a plan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\varsh\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\varsh\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\varsh\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\varsh\\anaconda3\\lib\\site-packages\\sklearn\\base.py:493: FutureWarning: The feature names should match those that were passed during fit. Starting version 1.2, an error will be raised.\n",
      "Feature names must be in the same order as they were in fit.\n",
      "\n",
      "  warnings.warn(message, FutureWarning)\n",
      "C:\\Users\\varsh\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\varsh\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\varsh\\anaconda3\\lib\\site-packages\\sklearn\\base.py:493: FutureWarning: The feature names should match those that were passed during fit. Starting version 1.2, an error will be raised.\n",
      "Feature names must be in the same order as they were in fit.\n",
      "\n",
      "  warnings.warn(message, FutureWarning)\n",
      "C:\\Users\\varsh\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\varsh\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\varsh\\anaconda3\\lib\\site-packages\\sklearn\\base.py:493: FutureWarning: The feature names should match those that were passed during fit. Starting version 1.2, an error will be raised.\n",
      "Feature names must be in the same order as they were in fit.\n",
      "\n",
      "  warnings.warn(message, FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>customer_ID</th>\n",
       "      <th>plan</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10000001</td>\n",
       "      <td>0013131</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10000002</td>\n",
       "      <td>2023132</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10000003</td>\n",
       "      <td>1013132</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10000004</td>\n",
       "      <td>2013133</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10000006</td>\n",
       "      <td>0013131</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  customer_ID     plan\n",
       "0    10000001  0013131\n",
       "1    10000002  2023132\n",
       "2    10000003  1013132\n",
       "3    10000004  2013133\n",
       "4    10000006  0013131"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Getting the predictions and preparing the kaggle submission file\n",
    "output_df=combine_sub_models_prediction(my_train,my_test,method='logistic')\n",
    "final_predictions_df=output_df[['customer_ID','plan']]\n",
    "final_predictions_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#EXPORTING THE FINAL RESULTS AS PDF FOR KAGGLE SUBMISSION\n",
    "final_predictions_df.to_csv(output_path+ 'Final_logistic_predictions.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. MODEL PREDICTIONS - USING RANDOM FOREST FOR ALL SUB MODELS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Models training results - using Random forests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Model 1 Training results- Prediction of G\n",
      "\n",
      "\n",
      "Training data size (77607, 144)\n",
      "validation data size (19402, 144)\n",
      "\n",
      "Using random_forest:\n",
      "'\n",
      "Using Random Forest - classification_report               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.81      0.85      0.83      4051\n",
      "           2       0.86      0.89      0.87      7556\n",
      "           3       0.92      0.87      0.90      6140\n",
      "           4       0.83      0.74      0.78      1655\n",
      "\n",
      "    accuracy                           0.86     19402\n",
      "   macro avg       0.85      0.84      0.85     19402\n",
      "weighted avg       0.86      0.86      0.86     19402\n",
      "\n",
      "Using Random Forest - Overall accuracy 0.8628491908050716\n",
      "\n",
      "Model 2 Training results- Prediction of C\n",
      "\n",
      "\n",
      "Training data size (77607, 144)\n",
      "validation data size (19402, 144)\n",
      "\n",
      "Using random_forest:\n",
      "'\n",
      "Using Random Forest - classification_report               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.94      0.94      0.94      5799\n",
      "           2       0.90      0.90      0.90      4078\n",
      "           3       0.93      0.95      0.94      7593\n",
      "           4       0.94      0.89      0.92      1932\n",
      "\n",
      "    accuracy                           0.93     19402\n",
      "   macro avg       0.93      0.92      0.92     19402\n",
      "weighted avg       0.93      0.93      0.93     19402\n",
      "\n",
      "Using Random Forest - Overall accuracy 0.9303164622203897\n",
      "\n",
      "Model 3 Training results- Prediction of D\n",
      "\n",
      "\n",
      "Training data size (77607, 145)\n",
      "validation data size (19402, 145)\n",
      "\n",
      "Using random_forest:\n",
      "'\n",
      "Using Random Forest - classification_report               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.89      0.94      0.91      2525\n",
      "           2       0.91      0.92      0.91      4335\n",
      "           3       0.98      0.96      0.97     12542\n",
      "\n",
      "    accuracy                           0.95     19402\n",
      "   macro avg       0.93      0.94      0.93     19402\n",
      "weighted avg       0.95      0.95      0.95     19402\n",
      "\n",
      "Using Random Forest - Overall accuracy 0.9508298113596536\n",
      "\n",
      "Model 4 Training results- Prediction of A\n",
      "\n",
      "\n",
      "Training data size (77607, 144)\n",
      "validation data size (19402, 144)\n",
      "\n",
      "Using random_forest:\n",
      "'\n",
      "Using Random Forest - classification_report               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.92      0.93      4276\n",
      "           1       0.93      0.96      0.95     11916\n",
      "           2       0.89      0.81      0.85      3210\n",
      "\n",
      "    accuracy                           0.93     19402\n",
      "   macro avg       0.92      0.90      0.91     19402\n",
      "weighted avg       0.93      0.93      0.93     19402\n",
      "\n",
      "Using Random Forest - Overall accuracy 0.9286156066384909\n",
      "\n",
      "Model 5 Training results- Prediction of F\n",
      "\n",
      "\n",
      "Training data size (77607, 145)\n",
      "validation data size (19402, 145)\n",
      "\n",
      "Using random_forest:\n",
      "'\n",
      "Using Random Forest - classification_report               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.97      0.96      6249\n",
      "           1       0.93      0.91      0.92      4793\n",
      "           2       0.92      0.94      0.93      7234\n",
      "           3       0.86      0.79      0.82      1126\n",
      "\n",
      "    accuracy                           0.93     19402\n",
      "   macro avg       0.92      0.90      0.91     19402\n",
      "weighted avg       0.93      0.93      0.93     19402\n",
      "\n",
      "Using Random Forest - Overall accuracy 0.9317080713328523\n",
      "\n",
      "Model 6 Training results- Prediction of B\n",
      "\n",
      "\n",
      "Training data size (77607, 144)\n",
      "validation data size (19402, 144)\n",
      "\n",
      "Using random_forest:\n",
      "'\n",
      "Using Random Forest - classification_report               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.95      0.94     10165\n",
      "           1       0.94      0.92      0.93      9237\n",
      "\n",
      "    accuracy                           0.93     19402\n",
      "   macro avg       0.93      0.93      0.93     19402\n",
      "weighted avg       0.93      0.93      0.93     19402\n",
      "\n",
      "Using Random Forest - Overall accuracy 0.9339243376971447\n",
      "\n",
      "Model 7 Training results- Prediction of E\n",
      "\n",
      "\n",
      "Training data size (77607, 145)\n",
      "validation data size (19402, 145)\n",
      "\n",
      "Using random_forest:\n",
      "'\n",
      "Using Random Forest - classification_report               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.95      0.94     10427\n",
      "           1       0.95      0.92      0.93      8975\n",
      "\n",
      "    accuracy                           0.94     19402\n",
      "   macro avg       0.94      0.94      0.94     19402\n",
      "weighted avg       0.94      0.94      0.94     19402\n",
      "\n",
      "Using Random Forest - Overall accuracy 0.9394392330687558\n"
     ]
    }
   ],
   "source": [
    "combine_sub_models_train(my_train,my_test,'random_forest')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Aggregating Model predictions in to a plan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>customer_ID</th>\n",
       "      <th>plan</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10000001</td>\n",
       "      <td>1011024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10000002</td>\n",
       "      <td>2113122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10000003</td>\n",
       "      <td>1013022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10000004</td>\n",
       "      <td>2011024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10000006</td>\n",
       "      <td>2011021</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  customer_ID     plan\n",
       "0    10000001  1011024\n",
       "1    10000002  2113122\n",
       "2    10000003  1013022\n",
       "3    10000004  2011024\n",
       "4    10000006  2011021"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Getting the predictions and preparing the kaggle submission file\n",
    "\n",
    "\n",
    "output_df=combine_sub_models_prediction(my_train,my_test,method='random_forest')\n",
    "final_predictions_df=output_df[['customer_ID','plan']]\n",
    "final_predictions_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "#EXPORTING THE FINAL RESULTS AS PDF FOR KAGGLE SUBMISSION\n",
    "final_predictions_df.to_csv(output_path+ 'Final_random_forest_predictions.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. MODEL PREDICTIONS - USING XGBOOST FOR ALL SUB MODELS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Models training results - using xgBOOST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Model 1 Training results- Prediction of G\n",
      "\n",
      "\n",
      "Training data size (77607, 144)\n",
      "validation data size (19402, 144)\n",
      "\n",
      "Using XGBOOST:\n",
      "'\n",
      "Using XGBOOST - classification_report               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.81      0.85      0.83      4051\n",
      "           2       0.86      0.89      0.87      7556\n",
      "           3       0.92      0.88      0.90      6140\n",
      "           4       0.83      0.75      0.79      1655\n",
      "\n",
      "    accuracy                           0.86     19402\n",
      "   macro avg       0.85      0.84      0.85     19402\n",
      "weighted avg       0.87      0.86      0.86     19402\n",
      "\n",
      "Using XGBOOST - Overall accuracy 0.8648592928564065\n",
      "\n",
      "Model 2 Training results- Prediction of C\n",
      "\n",
      "\n",
      "Training data size (77607, 144)\n",
      "validation data size (19402, 144)\n",
      "\n",
      "Using XGBOOST:\n",
      "'\n",
      "Using XGBOOST - classification_report               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.94      0.94      0.94      5799\n",
      "           2       0.90      0.90      0.90      4078\n",
      "           3       0.93      0.95      0.94      7593\n",
      "           4       0.94      0.90      0.92      1932\n",
      "\n",
      "    accuracy                           0.93     19402\n",
      "   macro avg       0.93      0.92      0.93     19402\n",
      "weighted avg       0.93      0.93      0.93     19402\n",
      "\n",
      "Using XGBOOST - Overall accuracy 0.9306257086898257\n",
      "\n",
      "Model 3 Training results- Prediction of D\n",
      "\n",
      "\n",
      "Training data size (77607, 145)\n",
      "validation data size (19402, 145)\n",
      "\n",
      "Using XGBOOST:\n",
      "'\n",
      "Using XGBOOST - classification_report               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.93      0.94      0.94      2525\n",
      "           2       0.93      0.93      0.93      4335\n",
      "           3       0.98      0.97      0.98     12542\n",
      "\n",
      "    accuracy                           0.96     19402\n",
      "   macro avg       0.94      0.95      0.95     19402\n",
      "weighted avg       0.96      0.96      0.96     19402\n",
      "\n",
      "Using XGBOOST - Overall accuracy 0.9595402535821049\n",
      "\n",
      "Model 4 Training results- Prediction of A\n",
      "\n",
      "\n",
      "Training data size (77607, 144)\n",
      "validation data size (19402, 144)\n",
      "\n",
      "Using XGBOOST:\n",
      "'\n",
      "Using XGBOOST - classification_report               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.93      0.94      4276\n",
      "           1       0.94      0.97      0.95     11916\n",
      "           2       0.90      0.81      0.85      3210\n",
      "\n",
      "    accuracy                           0.93     19402\n",
      "   macro avg       0.93      0.90      0.91     19402\n",
      "weighted avg       0.93      0.93      0.93     19402\n",
      "\n",
      "Using XGBOOST - Overall accuracy 0.9320688588805278\n",
      "\n",
      "Model 5 Training results- Prediction of F\n",
      "\n",
      "\n",
      "Training data size (77607, 145)\n",
      "validation data size (19402, 145)\n",
      "\n",
      "Using XGBOOST:\n",
      "'\n",
      "Using XGBOOST - classification_report               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.99      0.99      6249\n",
      "           1       0.94      0.91      0.92      4793\n",
      "           2       0.93      0.95      0.94      7234\n",
      "           3       0.91      0.86      0.88      1126\n",
      "\n",
      "    accuracy                           0.95     19402\n",
      "   macro avg       0.94      0.93      0.93     19402\n",
      "weighted avg       0.95      0.95      0.95     19402\n",
      "\n",
      "Using XGBOOST - Overall accuracy 0.9480465931347284\n",
      "\n",
      "Model 6 Training results- Prediction of B\n",
      "\n",
      "\n",
      "Training data size (77607, 144)\n",
      "validation data size (19402, 144)\n",
      "\n",
      "Using XGBOOST:\n",
      "'\n",
      "Using XGBOOST - classification_report               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.95      0.94     10165\n",
      "           1       0.94      0.92      0.93      9237\n",
      "\n",
      "    accuracy                           0.93     19402\n",
      "   macro avg       0.93      0.93      0.93     19402\n",
      "weighted avg       0.93      0.93      0.93     19402\n",
      "\n",
      "Using XGBOOST - Overall accuracy 0.9339243376971447\n",
      "\n",
      "Model 7 Training results- Prediction of E\n",
      "\n",
      "\n",
      "Training data size (77607, 145)\n",
      "validation data size (19402, 145)\n",
      "\n",
      "Using XGBOOST:\n",
      "'\n",
      "Using XGBOOST - classification_report               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.96      0.95     10427\n",
      "           1       0.95      0.94      0.94      8975\n",
      "\n",
      "    accuracy                           0.95     19402\n",
      "   macro avg       0.95      0.95      0.95     19402\n",
      "weighted avg       0.95      0.95      0.95     19402\n",
      "\n",
      "Using XGBOOST - Overall accuracy 0.9474796412740955\n"
     ]
    }
   ],
   "source": [
    "combine_sub_models_train(my_train,my_test,'XGBOOST')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Aggregating Model predictions in to a plan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>customer_ID</th>\n",
       "      <th>plan</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10000001</td>\n",
       "      <td>0011004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10000002</td>\n",
       "      <td>2023122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10000003</td>\n",
       "      <td>1021022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10000004</td>\n",
       "      <td>2011023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10000006</td>\n",
       "      <td>0011001</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  customer_ID     plan\n",
       "0    10000001  0011004\n",
       "1    10000002  2023122\n",
       "2    10000003  1021022\n",
       "3    10000004  2011023\n",
       "4    10000006  0011001"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Getting the predictions and preparing the kaggle submission file\n",
    "output_df=combine_sub_models_prediction(my_train,my_test,method='XGBOOST')\n",
    "final_predictions_df=output_df[['customer_ID','plan']]\n",
    "final_predictions_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "#EXPORTING THE FINAL RESULTS AS PDF FOR KAGGLE SUBMISSION\n",
    "final_predictions_df.to_csv(output_path+ 'Final_xgb_predictions.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
